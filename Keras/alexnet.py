# -*- coding: utf-8 -*-
"""AlexNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-OuMqPI7i5fAjfDJX78mZO5QNMjvRFD

# **LINEAR REGRESSION USING KERAS**
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.utils import to_categorical
import numpy as np
import time

"""*SET TENSORBOARD* <br>
Timestamp is used to create uniqueness
"""

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Scale to 0-1
x_train /= 255
x_test /= 255

batch_size = 32
num_classes = y_train.shape[1]
epochs = 20
learning_rate = 0.01

model_name = "AlexNet-E{}-LR{}-BS{}-{}".format(epochs, learning_rate, batch_size, int(time.time()))
tensorboard = TensorBoard(log_dir="logs/{}".format(model_name), write_images=True, write_graph=False)

"""# Architecture

```
padding="same"
```
*in order to adjust architecture to CIFAR-10 dataset*

**AlexNet: [paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)**
"""

def AlexNet(input_shape, num_classes):

  X_input = Input(input_shape)
  #-----------LAYER-1--------------
  Output_1 = Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding="same", input_shape=input_shape, activation="relu")(X_input)
  Layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding="same")(Output_1)
  #-----------LAYER-2--------------
  Output_2 = Conv2D(filters=256, kernel_size=(5,5), activation="relu", padding="same")(Layer_1)
  Layer_2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding="same")(Output_2)
  #-----------LAYER-3--------------
  Output_3 = Conv2D(filters=384, kernel_size=(3,3), activation="relu", padding="same")(Layer_2)
  #-----------LAYER-4--------------
  Output_4 = Conv2D(filters=384, kernel_size=(3,3), activation="relu", padding="same")(Output_3)
  #-----------LAYER-5--------------
  Output_5 = Conv2D(filters=256, kernel_size=(3,3), activation="relu", padding="same")(Output_4)
  Layer_5 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding="same")(Output_5)
  #-----------LAYER-6--------------
  Model_Output = Flatten()(Layer_5)
  Model_Output = Dense(units=4096, activation="relu")(Model_Output)
  #-----------LAYER-7--------------
  Model_Output = Dense(units=4096, activation="relu")(Model_Output)
  #-----------LAYER-8--------------OUTPUT
  Model_Output = Dense(units=num_classes, activation="softmax")(Model_Output)

  return Model(inputs = X_input, outputs = Model_Output)
  
model = AlexNet(x_train.shape[1:], 10)

sgd_opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)

model.compile(loss="categorical_crossentropy",
              optimizer=sgd_opt,
              metrics=["categorical_accuracy"])
model.summary()

tf.keras.backend.clear_session()

history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.33, verbose=1, callbacks=[tensorboard])

print(model_name)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir="logs/AlexNet-E20-LR0.01-BS32-1599724045"

"""# Plotting"""

print(history.history.keys())

import matplotlib.pyplot as plt
plt.plot(history.history['categorical_accuracy'])
plt.plot(history.history['val_categorical_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
#------------------------------------------------
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""# Evaluation"""

scores = model.evaluate(x_test, y_test, verbose=0)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

"""# Save and Load"""

# serialize model to JSON
model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")

from tensorflow.keras.models import model_from_json

# load json and create model
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model.h5")
print("Loaded model from disk")

# evaluate loaded model on test data
loaded_model.compile(loss='categorical_crossentropy', optimizer=sgd_opt, metrics=['categorical_accuracy'])
score = loaded_model.evaluate(x_test, y_test, verbose=0)
print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1]*100))

#save and load architecture and weights together
model.save("full_model.h5")
from tensorflow.keras.models import load_model
full_model = load_model('full_model.h5')
full_model.summary()

# evaluate loaded model on test data
full_model.compile(loss='categorical_crossentropy', optimizer=sgd_opt, metrics=['categorical_accuracy'])
score = full_model.evaluate(x_test, y_test, verbose=0)
print("%s: %.2f%%" % (full_model.metrics_names[1], score[1]*100))

